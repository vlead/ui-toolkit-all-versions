
Insights: 

Unlike insertion sort which has a runtime of $O(n^2)$, merge sort can
be seen to have a runtime of $O(n\log n)$. What helped in this case?

The big contributing factor is that in insertion sort, one can move an
element by only one position (left or right) at a time. Consdier an
element $x$ at index $i$, and $x$ has to be moved to index $j$ in sorted
order. Let  $|i-j| = k$. In each iteration of insertion sort, $x$ can
be moved only by one position. So, it takes $k$ moves for $x$ to be in
its right position. Notice that $k = \Theta(n)$, where $n$ is the size
of the input. Further, there can be $\Theta(n)$ elements with the
property that $k = \Theta(n)$. So, the overall runtime of insertion
sort is $O(n^2)$. 

In  merge sort however, an element can be moved by a distance as large
as $n/2$. In essence, an element can jump more than one cell at a time,
and hence the overall runtime does reduce. 

A further insight is that irrespective of the input, merge sort always
has a runtime of $O(n\log n)$. Notice that in each stage of the merge
sort, input is divided into two halves, each half is sorted, and the
sorted halves are merged. During the merge process, it is not
considered whether the input is already in sorted order or not. So, the
merge process proceedes oblivious to the input. On the other hand,
insertion sort can benefit on certain inputs. In fact, the number of
swaps that occur in an insertion sort is equal to the number of
inversions in the input data. An inversion is a pair of indices $i$ and
$j$ so that $A[i] > A[j]$ but $i <j$, i.e., elements are not in the
natural(sorted) order. For each such inversion pair, insertion sort has
to perform one swap. 

Problem: Use ideas from merge sort to design an algorithm to count the
number of inversions in a given set of elements.


Imagination: 

Notice that for merge sort to work, one does not need to know the
entire data at once. Consider settings where the entire data may not
fit into the memory of a computer system. In that case, one can bring
in as much data as it is possible to work with, sort in piece and then
write back the sorted piece, and bring fresh unsorted data in to the
memory. 

Once all data is sorted in pieces, these pieces can be then merged in a
similar fashion. 

This process is called as "external sorting'' as we imagine that the
data is available externally to the computer. Merge sort is one such
sorting algorithm that extends naturally to an external setting.

Problem: Develop the idea of external sorting using merge sort.
Describe the nature of data movements that are to be used in your
scheme. 

Problem: Why would insertion sort not work in an external setting?

Since it is clear that merge sort can work with only partial data, it
may be possible to think of a parallel version of merge sort. One can
view a parallel algorithm as follows. An algorithm is a sequence of
tasks $T1_, T_2, \cdots$. These tasks may have inter-dependecies, so
that task $T_i$ should be completed before task $T_j$ for some $i,j$.
However, it is often the case that there are several algorithms where
many tasks are independent of each other. (In some cases, the algorithm
or the computation has to be expressed in that indepedent-task
fashion). In such a setting, one can imagine that tasks that are
indepedent of each other can be done simultaneously, or in parallel.

Consider such parallel execution and the problem of sorting a given set
of numbers. When using merge sort, we divide the input into two parts.
These two tasks -- of sorting each part -- are independent of each
other and hence can be done in parallel. So let us investigate this
possibility further. We have to also merge sorted sequences. The way we
have described merge sort, when merging two sequences of length $\ell$
each, we have $2\ell$ tasks. These $2\ell$ tasks find the position of
each element in the two merged seuqences in the combined sequence of
$2\ell$ elements. These $2\ell$ tasks are also completely dependent in
the way they are written. However, a rewrite is possible. 

Let us call the two sorted sequences as $A$ and $B$. Think of searching
for each element of $A$ in $B$ and vice-versa. Since the sequences $A$
and $B$ are sorted, one can use binary search. Still there are $2\ell$
tasks but these $2\ell$ tasks are independent of each other. Once these
tasks finish, one can see that element $A[i]$ from $A$ can be placed at
index $i'$ where $i'= i + Rank(A[i], B)$. In the former expression,
$Rank(A[i], B)$ refers to the rank of element $A[i]$ in the array $B$
obtained using binary search. 

There are several enhancements to the above idea of a simple parallel
merge sort. An interested reader can find more details in the book ''An
Introduction to Parallel Algorithms'', by J. JaJa.
